{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.68769142e-01  3.56903171e-01  4.74138734e+00  2.20000000e+01]\n",
      "  [ 1.60076377e-01 -2.55609533e-01  4.55022910e+00  2.20000000e+01]\n",
      "  [ 1.14868731e+00 -6.24380156e-02  4.50385377e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.21266321e+00 -1.12853089e-01  3.04708757e+00 -2.11000000e+02]\n",
      "  [ 2.40893976e-01 -1.67174886e-02  2.82705667e+00  2.20000000e+01]\n",
      "  [ 1.02778452e-01 -8.58720522e-02  3.04180579e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.16829416e-01 -9.97057017e-01  5.32568913e-01  2.20000000e+01]\n",
      "  [ 2.31359397e-01 -1.59192211e+00  2.02906587e-01  2.20000000e+01]\n",
      "  [ 3.41572501e-01 -1.34588077e+00  1.79910012e-01  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.62305979e-01  1.30600679e+00  4.45584187e+00  3.21000000e+02]\n",
      "  [ 5.33720850e-01  1.27847224e+00  4.63907136e+00 -2.11200000e+03]\n",
      "  [ 8.22173394e-01  7.12645581e-01  4.70736440e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.31124336e-01 -6.34761724e-02  3.95621834e+00  2.20000000e+01]\n",
      "  [ 1.28517426e+00 -7.18495606e-02  3.79668946e+00 -2.11000000e+02]\n",
      "  [ 2.69184416e+00  2.79825145e-02  4.10518218e+00  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.04140138e-01  7.21628966e-01  1.25271426e+00  2.20000000e+01]\n",
      "  [ 9.00649058e-01  1.19311927e+00  1.03353543e+00  2.11000000e+02]\n",
      "  [ 1.54846983e-01  1.37730434e+00  1.24606922e+00  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "(100000, 139, 4)\n",
      "[1. 1. 1. ... 1. 0. 0.]\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(r\"C:\\Users\\YUVRAJ\\Videos\\Quark-Gluon\\root\\data\\X.npy\")\n",
    "y_train = np.load(r\"C:\\Users\\YUVRAJ\\Videos\\Quark-Gluon\\root\\data\\y.npy\")\n",
    "\n",
    "print(f\"{data}\\n{data.shape}\")\n",
    "print(f\"{y_train}\\n{y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_arr = []\n",
    "std_dev = []\n",
    "for i in range(0,4):\n",
    "    count_arr.append(np.count_nonzero(data[:,:,i]))\n",
    "sums_col = np.sum(data, axis=(0, 1))\n",
    "padd = np.all(data==0, axis=-1)\n",
    "for i in range(0,4):\n",
    "    std_dev.append(np.std(data[:, :, i][~padd]))\n",
    "\n",
    "data_norm = data.copy()\n",
    "def Z_score(x, std_arr, padd, count, sums_col):\n",
    "    x_train  = x.copy()   \n",
    "    for i in range(0,4):\n",
    "        mean = sums_col[i]/count[i]\n",
    "        x_train[:,:,i][~padd] = (x[:,:,i][~padd] - mean)/(std_arr[i]);\n",
    "    return x_train\n",
    "x_train = Z_score(data,std_dev,padd,count_arr, sums_col)\n",
    "\n",
    "cross_data = x_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.47854659  0.40339335  0.88090067  0.01229013]\n",
      "  [-0.48294452 -0.29421479  0.77591575  0.01229013]\n",
      "  [-0.44294329 -0.07420625  0.75044621 -0.4026803 ]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.44035469 -0.13162542 -0.04961606 -0.4026803 ]\n",
      "  [-0.47967447 -0.02213385 -0.17045798  0.01229013]\n",
      "  [-0.48526291 -0.10089595 -0.05251684  0.01229013]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.48064818 -1.13867042 -1.43060054  0.01229013]\n",
      "  [-0.48006026 -1.8161792  -1.61165251  0.01229013]\n",
      "  [-0.47560081 -1.53595572 -1.62428233  0.01229013]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.46666948  1.48435447  0.72407787  0.54480585]\n",
      "  [-0.4678261   1.45299458  0.8247083  -3.78834041]\n",
      "  [-0.45615471  0.8085585   0.86221513 -0.4026803 ]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.48006977 -0.07538864  0.44968247  0.01229013]\n",
      "  [-0.43742074 -0.08492533  0.36206853 -0.4026803 ]\n",
      "  [-0.38050398  0.02877626  0.53149406  0.34889706]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.4771154   0.81878994 -1.03509362  0.01229013]\n",
      "  [-0.45297942  1.35578366 -1.15546757  0.34889706]\n",
      "  [-0.48315611  1.56555727 -1.0387431   0.34889706]\n",
      "  ...\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.        ]]]\n",
      "(100000, 139, 4)\n",
      "[1. 1. 1. ... 1. 0. 0.]\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x_train}\\n{x_train.shape}\")\n",
    "print(f\"{y_train}\\n{y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YUVRAJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">825</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m71,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │           \u001b[38;5;34m825\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,574</span> (299.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,574\u001b[0m (299.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,574</span> (299.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,574\u001b[0m (299.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(128,activation='relu',input_shape = (556,)),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(25,activation='relu'),\n",
    "    Dense(12,activation='relu'),\n",
    "    Dense(1,activation='sigmoid',),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0737\n",
      "Epoch 2/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0605\n",
      "Epoch 3/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0510\n",
      "Epoch 4/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0563\n",
      "Epoch 5/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0521\n",
      "Epoch 6/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0571\n",
      "Epoch 7/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0452\n",
      "Epoch 8/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0423\n",
      "Epoch 9/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0438\n",
      "Epoch 10/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0388\n",
      "Epoch 11/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0429\n",
      "Epoch 12/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0445\n",
      "Epoch 13/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0421\n",
      "Epoch 14/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0439\n",
      "Epoch 15/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0320\n",
      "Epoch 16/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0446\n",
      "Epoch 17/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0427\n",
      "Epoch 18/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0334\n",
      "Epoch 19/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0418\n",
      "Epoch 20/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0372\n",
      "Epoch 21/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0316\n",
      "Epoch 22/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0320\n",
      "Epoch 23/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0396\n",
      "Epoch 24/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0297\n",
      "Epoch 25/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337\n",
      "Epoch 26/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0337\n",
      "Epoch 27/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0371\n",
      "Epoch 28/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0301\n",
      "Epoch 29/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0311\n",
      "Epoch 30/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0333\n",
      "Epoch 31/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0249\n",
      "Epoch 32/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0284\n",
      "Epoch 33/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0473\n",
      "Epoch 34/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0274\n",
      "Epoch 35/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0238\n",
      "Epoch 36/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0280\n",
      "Epoch 37/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0278\n",
      "Epoch 38/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0263\n",
      "Epoch 39/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0430\n",
      "Epoch 40/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0250\n",
      "Epoch 41/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0201\n",
      "Epoch 42/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0254\n",
      "Epoch 43/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0297\n",
      "Epoch 44/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0256\n",
      "Epoch 45/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0272\n",
      "Epoch 46/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0246\n",
      "Epoch 47/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0245\n",
      "Epoch 48/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0298\n",
      "Epoch 49/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0333\n",
      "Epoch 50/50\n",
      "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0236\n",
      "Epoch 1/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0660 - val_loss: 0.4311\n",
      "Epoch 2/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0415 - val_loss: 0.4331\n",
      "Epoch 3/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.4265\n",
      "Epoch 4/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0407 - val_loss: 0.4472\n",
      "Epoch 5/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0490 - val_loss: 0.4925\n",
      "Epoch 6/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.4679\n",
      "Epoch 7/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0366 - val_loss: 0.4695\n",
      "Epoch 8/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.4711\n",
      "Epoch 9/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.5580\n",
      "Epoch 10/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0464 - val_loss: 0.4497\n",
      "Epoch 11/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0397 - val_loss: 0.5034\n",
      "Epoch 12/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0366 - val_loss: 0.5351\n",
      "Epoch 13/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0472 - val_loss: 0.4880\n",
      "Epoch 14/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.5231\n",
      "Epoch 15/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0377 - val_loss: 0.5698\n",
      "Epoch 16/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0404 - val_loss: 0.5194\n",
      "Epoch 17/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.6111\n",
      "Epoch 18/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.5399\n",
      "Epoch 19/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.5793\n",
      "Epoch 20/20\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0305 - val_loss: 0.5628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ad14771cd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    ")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, random_state=34, test_size=0.3)\n",
    "\n",
    "model.fit(\n",
    "    \n",
    "    x_train,y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 50,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Accuracy: 88.0884%\n",
      "Confusion Matrix:\n",
      "[[6378  863]\n",
      " [ 888 6571]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.88      0.88      7241\n",
      "         1.0       0.88      0.88      0.88      7459\n",
      "\n",
      "    accuracy                           0.88     14700\n",
      "   macro avg       0.88      0.88      0.88     14700\n",
      "weighted avg       0.88      0.88      0.88     14700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "for i in range(0, len(y_pred)):\n",
    "    if(y_pred[i]>0.5):\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "Final = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100:.4f}%\")\n",
    "print(f\"Confusion Matrix:\\n{matrix}\")\n",
    "print(f\"Classification Report:\\n{Final}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
